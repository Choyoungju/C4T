{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjdwn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version :  1.10.0\n"
     ]
    }
   ],
   "source": [
    "from ner_model import predict\n",
    "from dataset import load_data\n",
    "import konlpy\n",
    "from konlpy.tag import Kkma\n",
    "import re\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag_Mapper():\n",
    "    def __init__(self,train_id_data,token_vocab,target_vocab):\n",
    "        self.traion_id_data = train_id_data\n",
    "        self.token_vocab = token_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        self.num_vocabs       = token_vocab.get_num_tokens()\n",
    "        self.num_target_class = target_vocab.get_num_targets()\n",
    "        \n",
    "    def AC_mapping(ac_list):\n",
    "        new_ac_list = []\n",
    "        for ac in ac_list:\n",
    "            words = Kkma().pos(ac)\n",
    "            for word in words:\n",
    "                if (word[1] not in ['NNM','NR','JC']) and (word[0] != '명'):\n",
    "                    new_ac_list.append(word[0])\n",
    "        return new_ac_list\n",
    "    \n",
    "    def PR_mapping(pr_list):\n",
    "        period = 0\n",
    "        period_str = ''\n",
    "        for pr in pr_list:\n",
    "            if '박' in pr:\n",
    "                p1 = re.compile('\\d+박')\n",
    "                p2 = re.compile('\\d+일')\n",
    "                pr1 = p1.findall(pr)\n",
    "                pr2 = p2.findall(pr)\n",
    "                if len(pr2) < 1:\n",
    "                    period = max(period,int(pr1[0][:-1]))\n",
    "                else:\n",
    "                    period = max(period,int(pr2[0][:-1]))\n",
    "            elif '일' in pr:\n",
    "                p1 = re.compile('\\d+월')\n",
    "                p2 = re.compile('\\d+일')\n",
    "                pr1= p1.findall(pr)\n",
    "                pr2= p2.findall(pr)\n",
    "                if len(pr1) == 2:\n",
    "                    period = max(period,30*(int(pr1[1][:-1])-int(pr1[0][:-1]))-int(pr2[0][:-1])+int(pr2[1][:-1]))\n",
    "                elif len(pr2) == 2:\n",
    "                    period = max(period,int(pr2[1][:-1])-int(pr2[0][:-1])+1)\n",
    "            elif '년' in pr and '월' not in pr:\n",
    "                period = 365\n",
    "            \n",
    "        if 0 < period <= 7:\n",
    "            period_str = '단기'\n",
    "        elif 7 < period <=30:\n",
    "            period_str = '중기'\n",
    "        else:\n",
    "            period_str = '장기'\n",
    "        \n",
    "        return period_str\n",
    "    \n",
    "    def WT_mapping(wt_list):\n",
    "        new_wt_list = []\n",
    "        for wt in wt_list:\n",
    "            words = Kkma().pos(wt)\n",
    "            for word in words:\n",
    "                if word[1] in ['NNM','NR','XR','NNG']:\n",
    "                    new_wt_list.append(word[0])\n",
    "        return new_wt_list\n",
    "    \n",
    "    def DT_mapping(dt_list):\n",
    "        season_list = ['봄','여름','가을','겨울']\n",
    "        new_dt_list = []\n",
    "        for dt in dt_list:\n",
    "            if dt in season_list: new_dt_list.append(dt)\n",
    "            if '월' in dt:\n",
    "                p = re.compile('\\d+월')\n",
    "                pr = p.findall(dt)\n",
    "                if len(pr) >= 2:\n",
    "                    pr = [int(d[:-1]) for d in pr]\n",
    "                    if pr[-1] >= pr[0]:\n",
    "                        new_dt_list+=list(range(pr[0],pr[-1]+1))\n",
    "                    else:\n",
    "                        new_dt_list= new_dt_list+ list(range(pr[0],13)) + list(range(1,pr[-1]+1))\n",
    "                elif len(pr) == 1:\n",
    "                    new_dt_list.append(int(pr[0][:-1]))\n",
    "                    \n",
    "        return set(new_dt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<common.nlp.data_loader.N2NTextData object at 0x000001A2B254CE10>\n"
     ]
    }
   ],
   "source": [
    "# train_id_data, token_vocab, target_vocab = load_data()\n",
    "# num_vocabs       = token_vocab.get_num_tokens()\n",
    "# num_target_class = target_vocab.get_num_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['딸', '어른', '부모님', '엄마', '아빠']\n"
     ]
    }
   ],
   "source": [
    "# def AC_mapping(ac_list):\n",
    "#     new_ac_list = []\n",
    "#     for ac in ac_list:\n",
    "#         words = Kkma().pos(ac)\n",
    "#         for word in words:\n",
    "#             if (word[1] not in ['NNM','NR','JC']) and (word[0] != '명'):\n",
    "#                 new_ac_list.append(word[0])\n",
    "#     return new_ac_list\n",
    "                \n",
    "# print(AC_mapping(['딸이랑','어른 2 명','부모님','엄마랑 아빠']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중기\n"
     ]
    }
   ],
   "source": [
    "# def PR_mapping(pr_list):\n",
    "#     period = 0\n",
    "#     period_str = ''\n",
    "#     for pr in pr_list:\n",
    "#         if '박' in pr:\n",
    "#             p1 = re.compile('\\d+박')\n",
    "#             p2 = re.compile('\\d+일')\n",
    "#             pr1 = p1.findall(pr)\n",
    "#             pr2 = p2.findall(pr)\n",
    "#             if len(pr2) < 1:\n",
    "#                 period = max(period,int(pr1[0][:-1]))\n",
    "#             else:\n",
    "#                 period = max(period,int(pr2[0][:-1]))\n",
    "#         elif '일' in pr:\n",
    "#             p1 = re.compile('\\d+월')\n",
    "#             p2 = re.compile('\\d+일')\n",
    "#             pr1= p1.findall(pr)\n",
    "#             pr2= p2.findall(pr)\n",
    "#             if len(pr1) == 2:\n",
    "#                 period = max(period,30*(int(pr1[1][:-1])-int(pr1[0][:-1]))-int(pr2[0][:-1])+int(pr2[1][:-1]))\n",
    "#             elif len(pr2) == 2:\n",
    "#                 period = max(period,int(pr2[1][:-1])-int(pr2[0][:-1])+1)\n",
    "#         elif '년' in pr and '월' not in pr:\n",
    "#             period = 365\n",
    "            \n",
    "#     if 0 < period <= 7:\n",
    "#         period_str = '단기'\n",
    "#     elif 7 < period <=30:\n",
    "#         period_str = '중기'\n",
    "#     else:\n",
    "#         period_str = '장기'\n",
    "        \n",
    "#     return period_str\n",
    "                             \n",
    "# print(PR_mapping(['1일','2018년3월3일', '3월12일 부터 14일 까지','3일~13일','5일']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['따뜻', '찝찝', '건기', '비', '눈']\n"
     ]
    }
   ],
   "source": [
    "# def WT_mapping(wt_list):\n",
    "#     new_wt_list = []\n",
    "#     for wt in wt_list:\n",
    "#         words = Kkma().pos(wt)\n",
    "#         for word in words:\n",
    "#             if word[1] in ['NNM','NR','XR','NNG']:\n",
    "#                 new_wt_list.append(word[0])\n",
    "#     return new_wt_list\n",
    "    \n",
    "                             \n",
    "# print(WT_mapping(['따뜻한','찝찝한', '건기','비 오는','눈 내리는']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 10, 11, 12, 2, 5, 8, 9, '겨울'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def DT_mapping(dt_list):\n",
    "#     season_list = ['봄','여름','가을','겨울']\n",
    "#     new_dt_list = []\n",
    "#     for dt in dt_list:\n",
    "#         if dt in season_list: new_dt_list.append(dt)\n",
    "#         if '월' in dt:\n",
    "#             p = re.compile('\\d+월')\n",
    "#             pr = p.findall(dt)\n",
    "#             if len(pr) >= 2:\n",
    "#                 pr = [int(d[:-1]) for d in pr]\n",
    "#                 if pr[-1] >= pr[0]:\n",
    "#                     new_dt_list+=list(range(pr[0],pr[-1]+1))\n",
    "#                 else:\n",
    "#                     new_dt_list= new_dt_list+ list(range(pr[0],13)) + list(range(1,pr[-1]+1))\n",
    "#             elif len(pr) == 1:\n",
    "#                 new_dt_list.append(int(pr[0][:-1]))\n",
    "                    \n",
    "\n",
    "#     return set(new_dt_list)\n",
    "    \n",
    "                             \n",
    "# DT_mapping(['5월','8월~11월','12월-2월','겨울'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['칠레', '필리핀', '독일']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LC_mapping(lc_list):\n",
    "    lc_dict= defaultdict(lambda: [])\n",
    "    with open('./data/country_city_map.csv',encoding='utf8') as f:\n",
    "        reader = list(csv.reader(f))\n",
    "        for line in reader[1:]:\n",
    "            lc_dict[line[1]].append(line[0])\n",
    "    lc_keys = lc_dict.keys()\n",
    "    for lc in lc_list:\n",
    "        for key in lc_keys:\n",
    "            if lc in lc_dict[key]:\n",
    "                lc_list.remove(lc)\n",
    "                lc_list.append(key)\n",
    "    return lc_list\n",
    "                             \n",
    "LC_mapping(['보라카이','칠레','베를린'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_mapping(tag_dict):\n",
    "        tag_dict['AC'] = AC_mapping(list(tag_dict['AC']))\n",
    "        tag_dict['PR'] = PR_mapping(list(tag_dict['PR']))\n",
    "        #tag_dict['PU'] = PU_mapping(list(tag_dict['PU']))\n",
    "        tag_dict['WT'] = WT_mapping(list(tag_dict['WT']))\n",
    "        tag_dict['DT'] = DT_mapping(list(tag_dict['DT']))\n",
    "        tag_dict['LC'] = LC_mapping(list(tag_dict['LC']))\n",
    "        return tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_tag_dict(sent,tags):\n",
    "    tag_dict = defaultdict(lambda: set())\n",
    "    word=''\n",
    "    is_tag = False\n",
    "    for index in range(len(tags)) :\n",
    "        if tags[index] is not 'O':\n",
    "            word+=sent[index]\n",
    "            is_tag = True\n",
    "            continue\n",
    "        if is_tag:\n",
    "            if len(word) <= 1: word='';continue          \n",
    "            tag_dict[tags[index-len(word)][-2:]].add(word)\n",
    "            is_tag = False\n",
    "            word=''\n",
    "    mapped_dict = tag_mapping(tag_dict)\n",
    "    return mapped_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': {3}, 'AC': [], 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'DT': {10, 11, 12}, 'AC': ['부모님'], 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'DT': {9}, 'AC': ['친구'], 'PU': {'경비'}, 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'AC': ['친구'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'DT': {11}, 'PR': '단기', 'AC': [], 'WT': [], 'LC': []}\n",
      "{'LC': ['보라카'], 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'LC': ['세부', '대만', '방콕', '베트남'], 'PU': {'먹방'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'PU': {'다낭'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PU': {'힐링', '휴양', '관광'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['어', '어', '머', '가족'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PR': '단기', 'AC': ['어', '어', '머', '아이'], 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PU': {'물놀'}, 'LC': ['사이판'], 'PR': '단기', 'AC': [], 'WT': [], 'DT': set()}\n",
      "{'PU': {'휴양', '놀고', '바다', '수영장'}, 'WT': [], 'AC': [], 'PR': '장기', 'DT': set(), 'LC': []}\n",
      "{'AC': ['친구', '두'], 'PU': {'돈모'}, 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['형편'], 'PU': {'구경'}, 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PR': '장기', 'DT': {'겨울'}, 'AC': [], 'WT': [], 'LC': []}\n",
      "{'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['가족', '아이', '초등'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'DT': {'여름'}, 'AC': ['가족'], 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'AC': ['가족'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'LC': ['동남아', '일본'], 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'PU': {'골프'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PU': {'음식'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['부모님'], 'DT': {9}, 'LC': ['세부', '코타', '베트남'], 'PR': '장기', 'WT': []}\n",
      "{'AC': ['부모님'], 'PU': {'힐링'}, 'PR': '단기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'LC': ['일본'], 'PR': '장기', 'AC': [], 'WT': [], 'DT': set()}\n",
      "{'DT': {6}, 'AC': ['가족'], 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'AC': ['유아'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['가족'], 'PU': {'다리'}, 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PU': {'볼거리'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['가족'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'DT': {12}, 'AC': [], 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'LC': ['티켓', '일본', '보라카이', '세부', '마카오', '홍콩'], 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'DT': {'여름'}, 'AC': ['~', '엄마', '여동생'], 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'AC': ['엄마'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PU': {'구경'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['친구', '두'], 'PU': {'돈모'}, 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['형편'], 'PU': {'구경'}, 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'PR': '장기', 'DT': {'겨울'}, 'AC': [], 'WT': [], 'LC': []}\n",
      "{'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['어머니'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['어머니', '여동생'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['어머니'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'LC': ['동남아', '태국'], 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'DT': set(), 'AC': ['아니'], 'PR': '장기', 'WT': [], 'LC': []}\n",
      "{'AC': ['어머니', '혼자'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'LC': ['루미큐브'], 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'AC': ['여자', '친구'], 'PR': '단기', 'PU': {'음식'}, 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'AC': ['친구'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'DT': {'겨울'}, 'PR': '장기', 'AC': [], 'WT': [], 'LC': []}\n",
      "{'DT': {2}, 'LC': ['일본', '일본'], 'PR': '중기', 'AC': [], 'WT': []}\n",
      "{'LC': ['도쿄', '일본', '일본'], 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'AC': ['부모님'], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'DT': {11}, 'PR': '단기', 'AC': [], 'WT': [], 'LC': []}\n",
      "{'PU': {'휴양', '트레킹', '자연'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'LC': ['스위스'], 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'LC': ['캐나'], 'PU': {'날씨'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'DT': {12}, 'PR': '중기', 'AC': [], 'WT': [], 'LC': []}\n",
      "{'LC': ['유럽'], 'PU': {'스피킹'}, 'AC': [], 'PR': '장기', 'WT': [], 'DT': set()}\n",
      "{'PR': '중기', 'AC': ['혼자'], 'PU': {'휴양'}, 'WT': [], 'DT': set(), 'LC': []}\n",
      "{'DT': {12}, 'AC': [], 'PR': '장기', 'WT': [], 'LC': []}\n"
     ]
    }
   ],
   "source": [
    " with open('./data/trip.test.txt',encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            sent, targets = predict(token_vocab, target_vocab,line)\n",
    "            print(dict(sent_tag_dict(sent,targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "sent = '2018/12/7~12/13'\n",
    "words = Kkma().pos(sent)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "df = pd.read_clipboard(engine='python',sep='\\n')\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv('countries.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_lines = []\n",
    "with open('countries.csv',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = '<%s:LC>'%line.strip()\n",
    "        new_lines.append(line)\n",
    "with codecs.open('countries.csv','w',encoding='utf-8') as f:\n",
    "    for line in new_lines:\n",
    "        print(line,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = {'a':'[1,2,3]'}\n",
    "ac['a'] = 'a'\n",
    "print(ac['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import nltk\n",
    "\n",
    "# POS tag a sentence\n",
    "sentence = u'비가 오는 눈 내리는'\n",
    "words = konlpy.tag.Kkma().pos(sentence)\n",
    "\n",
    "# Define a chunk grammar, or chunking rules, then chunk\n",
    "grammar = \"\"\"\n",
    "NP: {<N.*>*<Suffix>?}   # Noun phrase\n",
    "VP: {<V.*>*}            # Verb phrase\n",
    "AP: {<A.*>*}            # Adjective phrase\n",
    "\"\"\"\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "chunks = parser.parse(words)\n",
    "print(\"# Print whole tree\")\n",
    "print(chunks.pprint())\n",
    "\n",
    "print(\"\\n# Print noun phrases only\")\n",
    "for subtree in chunks.subtrees():\n",
    "    if subtree.label()=='NP':\n",
    "        print(' '.join((e[0] for e in list(subtree))))\n",
    "        print(subtree.pprint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['a','b']\n",
    "b = ['x','y']\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
