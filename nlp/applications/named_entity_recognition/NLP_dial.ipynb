{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjdwn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version :  1.10.0\n"
     ]
    }
   ],
   "source": [
    "from ner_model import predict\n",
    "from dataset import load_data\n",
    "import konlpy\n",
    "from konlpy.tag import Kkma\n",
    "import re\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag_Mapper():\n",
    "    def __init__(self,token_vocab,target_vocab,sent):\n",
    "        self.sent = sent\n",
    "        self.token_vocab = token_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        \n",
    "        def AC_mapping(ac_list):\n",
    "            new_ac_list = []\n",
    "            for ac in ac_list:\n",
    "                words = Kkma().pos(ac)\n",
    "                for word in words:\n",
    "                    if (word[1] not in ['NNM','NR','JC']) and (word[0] != '명'):\n",
    "                        new_ac_list.append(word[0])\n",
    "            return new_ac_list\n",
    "\n",
    "        def PR_mapping(pr_list):\n",
    "            period = 0\n",
    "            period_str = ''\n",
    "            for pr in pr_list:\n",
    "                if '박' in pr:\n",
    "                    p1 = re.compile('\\d+박')\n",
    "                    p2 = re.compile('\\d+일')\n",
    "                    pr1 = p1.findall(pr)\n",
    "                    pr2 = p2.findall(pr)\n",
    "                    if len(pr2) < 1:\n",
    "                        period = max(period,int(pr1[0][:-1]))\n",
    "                    else:\n",
    "                        period = max(period,int(pr2[0][:-1]))\n",
    "                elif '일' in pr:\n",
    "                    p1 = re.compile('\\d+월')\n",
    "                    p2 = re.compile('\\d+일')\n",
    "                    pr1= p1.findall(pr)\n",
    "                    pr2= p2.findall(pr)\n",
    "                    if len(pr1) == 2:\n",
    "                        period = max(period,30*(int(pr1[1][:-1])-int(pr1[0][:-1]))-int(pr2[0][:-1])+int(pr2[1][:-1]))\n",
    "                    elif len(pr2) == 2:\n",
    "                        period = max(period,int(pr2[1][:-1])-int(pr2[0][:-1])+1)\n",
    "                elif '년' in pr and '월' not in pr:\n",
    "                    period = 365\n",
    "\n",
    "            if 0 < period <= 7:\n",
    "                period_str = '단기'\n",
    "            elif 7 < period <=30:\n",
    "                period_str = '중기'\n",
    "            else:\n",
    "                period_str = '장기'\n",
    "\n",
    "            return period_str\n",
    "\n",
    "        def WT_mapping(wt_list):\n",
    "            new_wt_list = []\n",
    "            for wt in wt_list:\n",
    "                words = Kkma().pos(wt)\n",
    "                for word in words:\n",
    "                    if word[1] in ['NNM','NR','XR','NNG']:\n",
    "                        new_wt_list.append(word[0])\n",
    "            return new_wt_list\n",
    "\n",
    "        def DT_mapping(dt_list):\n",
    "            season_list = ['봄','여름','가을','겨울']\n",
    "            new_dt_list = []\n",
    "            for dt in dt_list:\n",
    "                if dt in season_list: new_dt_list.append(dt)\n",
    "                if '월' in dt:\n",
    "                    p = re.compile('\\d+월')\n",
    "                    pr = p.findall(dt)\n",
    "                    if len(pr) >= 2:\n",
    "                        pr = [int(d[:-1]) for d in pr]\n",
    "                        if pr[-1] >= pr[0]:\n",
    "                            new_dt_list+=list(range(pr[0],pr[-1]+1))\n",
    "                        else:\n",
    "                            new_dt_list= new_dt_list+ list(range(pr[0],13)) + list(range(1,pr[-1]+1))\n",
    "                    elif len(pr) == 1:\n",
    "                        new_dt_list.append(int(pr[0][:-1]))\n",
    "\n",
    "            return list(set(new_dt_list))\n",
    "\n",
    "        def LC_mapping(lc_list):\n",
    "            lc_dict= defaultdict(lambda: [])\n",
    "            with open('./data/country_city_map.csv',encoding='utf8') as f:\n",
    "                reader = list(csv.reader(f))\n",
    "                for line in reader[1:]:\n",
    "                    lc_dict[line[1]].append(line[0])\n",
    "            lc_keys = lc_dict.keys()\n",
    "            for lc in lc_list:\n",
    "                for key in lc_keys:\n",
    "                    if lc in lc_dict[key]:\n",
    "                        lc_list.remove(lc)\n",
    "                        lc_list.append(key)\n",
    "            return lc_list\n",
    "        \n",
    "         def PU_mapping(pu_list):\n",
    "            return pu_list\n",
    "\n",
    "        def tag_mapping(tag_dict):\n",
    "            tag_dict['AC'] = AC_mapping(list(tag_dict['AC']))\n",
    "            tag_dict['PR'] = PR_mapping(list(tag_dict['PR']))\n",
    "            tag_dict['PU'] = PU_mapping(list(tag_dict['PU']))\n",
    "            tag_dict['WT'] = WT_mapping(list(tag_dict['WT']))\n",
    "            tag_dict['DT'] = DT_mapping(list(tag_dict['DT']))\n",
    "            tag_dict['LC'] = LC_mapping(list(tag_dict['LC']))\n",
    "            return tag_dict\n",
    "\n",
    "        def sent_tag_dict(sent,targets):\n",
    "            tag_dict = defaultdict(lambda: set())\n",
    "            word=''\n",
    "            is_tag = False\n",
    "            for index in range(len(targets)) :\n",
    "                if targets[index] is not 'O':\n",
    "                    word+=sent[index]\n",
    "                    is_tag = True\n",
    "                    continue\n",
    "                if is_tag:\n",
    "                    if len(word) <= 1: word='';continue          \n",
    "                    tag_dict[targets[index-len(word)][-2:]].add(word)\n",
    "                    is_tag = False\n",
    "                    word=''\n",
    "            mapped_dict = tag_mapping(tag_dict)\n",
    "            return mapped_dict\n",
    "\n",
    "        sent, targets = predict(self.token_vocab, self.target_vocab,self.sent)\n",
    "        self.mapped_dict = sent_tag_dict(sent,targets)\n",
    "        \n",
    "    def get_dict(self):\n",
    "        return self.mapped_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PR': '단기', 'AC': ['엄마'], 'LC': ['필리핀'], 'WT': ['따뜻'], 'DT': [8]}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_id_data, token_vocab, target_vocab = load_data()\n",
    "    mapp = Tag_Mapper(token_vocab,target_vocab,'3박4일 엄마랑 보라카이로 따뜻한 곳으로 8월에 휴가갈거야')\n",
    "    print(dict(mapp.get_dict()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
